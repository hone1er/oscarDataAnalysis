{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "from tmdb_config import API_KEY\n",
    "from pprint import pprint\n",
    "\n",
    "# Import csv file\n",
    "#movie_data = pd.read_csv(\"bestPic2018Data.csv\")\n",
    "#movie_data = pd.read_csv(\"bestPic2016-2017Data.csv\")\n",
    "movie_data = pd.read_csv(\"bestactress_20161718.csv\")\n",
    "\n",
    "#movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of movie titles to query\n",
    "movies = movie_data['movieName']\n",
    "#movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the endpoint URL\n",
    "url = 'https://api.themoviedb.org/3/search/movie?'\n",
    "api_key = f'api_key={API_KEY}&query='\n",
    "\n",
    "# set up lists to hold response data:\n",
    "movie_id = []\n",
    "genres = []\n",
    "original_language = []\n",
    "original_title = []\n",
    "overview = []\n",
    "popularity = []\n",
    "title = []\n",
    "vote_average = []\n",
    "vote_count = []\n",
    "\n",
    "# junk list\n",
    "junk_list = []\n",
    "\n",
    "# loop through movie titles, make requests and parse\n",
    "for movie in movies :\n",
    "    response = requests.get(url + api_key + movie).json()\n",
    "    try:\n",
    "        movie_id.append(response['results'][0]['id'])\n",
    "        genres.append(response['results'][0]['genre_ids'])\n",
    "        original_language.append(response['results'][0]['original_language'])\n",
    "        original_title.append(response['results'][0]['original_title'])\n",
    "        overview.append(response['results'][0]['overview'])\n",
    "        popularity.append(response['results'][0]['popularity'])\n",
    "        title.append(response['results'][0]['title'])\n",
    "        vote_average.append(response['results'][0]['vote_average'])\n",
    "        vote_count.append(response['results'][0]['vote_count'])\n",
    "\n",
    "    except:\n",
    "        #print(movie, response)\n",
    "        junk_list.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18], [18], [18], [18, 36], [18], [18], [18], [18, 10749], [35, 18], [18, 14, 10749], [18, 36, 35], [18], [18, 10749, 80], [18, 36, 35]]\n",
      "[[{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name': 'History'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}], [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10749, 'name': 'Romance'}], [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name': 'History'}, {'id': 35, 'name': 'Comedy'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}, {'id': 80, 'name': 'Crime'}], [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name': 'History'}, {'id': 35, 'name': 'Comedy'}]]\n"
     ]
    }
   ],
   "source": [
    "#print(junk_list)\n",
    "import ast\n",
    "from pandas.io.json import json_normalize \n",
    "url = 'https://api.themoviedb.org/3/genre/movie/list?'\n",
    "api_key = f'api_key={API_KEY}&language=en-US'\n",
    "#genres_mapping = []\n",
    "response = requests.get(url + api_key  ).json()\n",
    "data = response\n",
    "df = json_normalize(data, 'genres')\n",
    "#data.set_index('Locality', inplace=True)\n",
    "df = df.set_index('id')\n",
    "#print (df)\n",
    "# \n",
    "# json_str = json.dumps(data)\n",
    "# data = json.loads(json_str)\n",
    "# print((data))\n",
    "print(genres)\n",
    "genres_cleaned = []\n",
    "for genre in genres:\n",
    "    #print(genre)\n",
    "    genre_name = []\n",
    "    for i in genre:\n",
    "        genre_new = {}\n",
    "        genre_new[\"id\"] = i\n",
    "        #genre_name.append()\n",
    "        genre_new[\"name\"] = df.loc[i,'name']\n",
    "        genre_name.append(genre_new)\n",
    "    #genre_new = dict(zip(\"id\":genre, \"name\":genre_name))\n",
    "    genres_cleaned.append(genre_name)\n",
    "# print(genres_cleaned)\n",
    "#(genres_cleaned).replace(\"'\", '\"')\n",
    "print(genres_cleaned)\n",
    "#genres_data = json.dumps(ast.literal_eval(genres_cleaned))\n",
    "# genres_clean = json.dumps(genres_cleaned)\n",
    "# print(genres_clean)\n",
    "    #[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making a pass to get more detailed data, have to use ids\n",
    "\n",
    "# Build the endpoint URL\n",
    "url = 'https://api.themoviedb.org/3/year/'\n",
    "api_key = f'?api_key={API_KEY}&query='\n",
    "\n",
    "budget = []\n",
    "production_companies = []\n",
    "production_countries = []\n",
    "status = []\n",
    "tagline = []\n",
    "release_date = []\n",
    "revenue = []\n",
    "runtime = []\n",
    "spoken_languages = []\n",
    "\n",
    "# loop through movie ids, make requests and parse\n",
    "for movie in movie_id :\n",
    "    response = requests.get(url + str(movie) + api_key).json()\n",
    "    try:\n",
    "        budget.append(response['budget'])\n",
    "        production_companies.append(response['production_companies'])\n",
    "        production_countries.append(response['production_countries'])\n",
    "        status.append(response['status'])\n",
    "        tagline.append(response['tagline'])\n",
    "        release_date.append(response['release_date'])        \n",
    "        revenue.append(response['revenue'])\n",
    "        runtime.append(response['runtime'])\n",
    "        spoken_languages.append(response['spoken_languages'])\n",
    "    except:\n",
    "        #print(movie, response)\n",
    "        junk_list.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a pass to get cast data, have to use ids\n",
    "\n",
    "# Build the endpoint URL\n",
    "url = 'https://api.themoviedb.org/3/movie/'\n",
    "api_key = f'/credits?api_key={API_KEY}&query='\n",
    "\n",
    "cast = []\n",
    "crew = []\n",
    "\n",
    "# loop through movie ids, make requests and parse\n",
    "for movie in movie_id :\n",
    "    response = requests.get(url + str(movie) + api_key).json()\n",
    "    try:\n",
    "        cast.append(response['cast'])\n",
    "        crew.append(response['crew'])\n",
    "    except:\n",
    "        #print(movie, response)\n",
    "        junk_list.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a pass to get keywords data, have to use ids\n",
    "\n",
    "# Build the endpoint URL\n",
    "url = 'https://api.themoviedb.org/3/movie/'\n",
    "api_key = f'/keywords?api_key={API_KEY}&query='\n",
    "\n",
    "keywords = []\n",
    "\n",
    "# loop through movie ids, make requests and parse\n",
    "for movie in movie_id :\n",
    "    response = requests.get(url + str(movie) + api_key).json()\n",
    "    try:\n",
    "        keywords.append(response['keywords'])\n",
    "    except:\n",
    "        #print(movie, response)\n",
    "        junk_list.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name': 'History'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}], [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10749, 'name': 'Romance'}], [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name': 'History'}, {'id': 35, 'name': 'Comedy'}], [{'id': 18, 'name': 'Drama'}], [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}, {'id': 80, 'name': 'Crime'}], [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name': 'History'}, {'id': 35, 'name': 'Comedy'}]]\n"
     ]
    }
   ],
   "source": [
    "# This Block for sorting through errors\n",
    "print(genres_cleaned)\n",
    "#print(\"Length of Ranks Series: \" , len(ranks))\n",
    "#for junk in junk_list:\n",
    "#    print(junk)\n",
    "#    i=movies[movies==junk]\n",
    "#    print(i.index, i.index[0])\n",
    "#    ranks = ranks.drop(i.index[0])\n",
    "#print(\"Length of Ranks Series: \" , len(ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-090db51ba07f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m'tagline'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtagline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m'vote_average'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mvote_average\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;34m'vote_count'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mvote_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m })\n\u001b[1;32m     25\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/machinelearning/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/machinelearning/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/machinelearning/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/machinelearning/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "# save data to pandas dataframe\n",
    "movies_df = pd.DataFrame({\n",
    "    'title' : title,\n",
    "    'cast' : cast,\n",
    "    'crew' : crew,\n",
    "    'budget' : budget,\n",
    "    'genres_new' : genres_cleaned,\n",
    "    'movie_id' : movie_id,\n",
    "    'keywords' : keywords,\n",
    "    'original_language' : original_language,\n",
    "    'original_title' : original_title,\n",
    "    'overview' : overview,\n",
    "    'popularity' : popularity,\n",
    "    'production_companies' : production_companies,\n",
    "    'production_countries' : production_countries,\n",
    "    'release_date' : release_date,\n",
    "    'revenue' : revenue,\n",
    "    'runtime' : runtime,\n",
    "    'spoken_languages' : spoken_languages,\n",
    "    'status' : status,\n",
    "    'tagline' : tagline,\n",
    "    'vote_average' : vote_average,\n",
    "    'vote_count' : vote_count\n",
    "})\n",
    "movies_df.tail()\n",
    "# movies_df.genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies_df.to_csv('2018_best_picture_tmdb.csv', index=False)\n",
    "movies_df.to_csv('2016_2017_best_actresssupport_tmdb2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
