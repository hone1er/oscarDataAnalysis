{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'BECHDEL___masterList.csv' does not exist: b'BECHDEL___masterList.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3ebb0ae49541>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m df = pd.read_csv(\"BECHDEL___masterList.csv\", dtype={'budget': float, 'revenue': float, \n\u001b[1;32m----> 3\u001b[1;33m                                                     'vote_count': float, 'Bechdel_Test': float})\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'BECHDEL___masterList.csv' does not exist: b'BECHDEL___masterList.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"BECHDEL___masterList.csv\", dtype={'budget': float, 'revenue': float, \n",
    "                                                    'vote_count': float, 'Bechdel_Test': float})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['revenue', 'popularity', 'budget', 'vote_average', 'vote_count'], axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Pre-OneHot Encoding Plots ######\n",
    "#######################################\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Count of Failed Bechdel Tests Films: \", len(df.loc[df['Bechdel_Test'] == 0]))\n",
    "print(\"\\nCount of Passed Bechdel Tests Films: \", len(df.loc[df['Bechdel_Test'] == 1]))\n",
    "\n",
    "# Basic Bar Graph compares films passing the Bechdel Test vs. films failing.\n",
    "derp = sns.countplot(x='Bechdel_Test', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap Correlation Analysis\n",
    "g = sns.heatmap(df[['runtime', 'winner', 'Bechdel_Test']].corr(),cmap='RdYlGn',annot=True)\n",
    "\n",
    "print(\"The strongest correlating attribute of Winning = Revenue\\n\\nThere also appear to be other moderate (+70%) correlations of: \\n---Budget/Revenue, \\n---Popularity/Vote_Count, \\n---Revenue/Vote_Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(df[['winner', 'Bechdel_Test']].corr(),cmap='RdYlGn',annot=True)\n",
    "\n",
    "print(\"There is small ~10% correlation to Winning/Passed-Bechdel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density Curve: Bechel Test\n",
    "bTest0 = df[df['winner'] == 0]['Bechdel_Test']\n",
    "bTest1 = df[df['winner'] == 1]['Bechdel_Test']\n",
    "\n",
    "g = sns.kdeplot(bTest0, legend = True, shade=True, color='r', label = 'non-nominated')\n",
    "g = sns.kdeplot(bTest1, legend = True, shade=True, color='b', label = 'nominated')\n",
    "\n",
    "print(\"X Axis:\\n\\n---0.0 = Failed Bechdel Test\\n---1.0 = Passed Bechdel Test\")\n",
    "#todo:::   change the x ticks to represent that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "genres_name0 = {}\n",
    "genres_name1 = {}\n",
    "genres_set = set()\n",
    "\n",
    "# Fancy Itterrows() looks for Bechdel_Test result bool, if a dictionary with the name of the\n",
    "# current movie doesn't exist in the genres_name0/1 then one is appended with a tally count\n",
    "# of 1. If a dict already exists then the tally count is increased by 1.\n",
    "for i in range(len(df)):\n",
    "    genres = json.loads(df.loc[i,'genres'])\n",
    "    for it in genres:\n",
    "        genres_set.add(it['name'])\n",
    "        if df.loc[i,'Bechdel_Test'] == 0:\n",
    "            if it['name'] not in genres_name0:\n",
    "                genres_name0[it['name']] = 1\n",
    "            else:\n",
    "                genres_name0[it['name']] += 1\n",
    "        if df.loc[i,'Bechdel_Test'] == 1:\n",
    "            if it['name'] not in genres_name1:\n",
    "                genres_name1[it['name']] = 1\n",
    "            else:\n",
    "                genres_name1[it['name']] += 1\n",
    "            \n",
    "genres_array0=[]\n",
    "genres_array1=[]\n",
    "\n",
    "# Binning of Genre names\n",
    "for g in genres_set:\n",
    "    if g in genres_name0:\n",
    "        genres_array0.append(genres_name0[g])\n",
    "    else:\n",
    "        genres_array0.append(0)\n",
    "    if g in genres_name1:\n",
    "        genres_array1.append(genres_name1[g])\n",
    "    else:\n",
    "        genres_array1.append(0)\n",
    "\n",
    "# NumPy % of whole calculations for upcoming plot\n",
    "genres_all = []\n",
    "genres_all.append(np.array(genres_array0)/sum(genres_array0))\n",
    "genres_all.append(np.array(genres_array1)/sum(genres_array1))\n",
    "\n",
    "# New DF creation to hold the by-Genre data\n",
    "df_genres = pd.DataFrame(genres_all, columns=list(genres_set))\n",
    "df_genres[['budget','popularity','revenue','runtime','vote_average','vote_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Bars: Bechdel Test % / Movie Genres\n",
    "N = len(df_genres.columns)\n",
    "ind = np.arange(N)\n",
    "width = 0.5\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "p1 = plt.bar(ind, df_genres.loc[[0]].values[0], width, color='#d62728')\n",
    "p2 = plt.bar(ind, df_genres.loc[[1]].values[0], width, bottom=df_genres.loc[[0]].values[0])\n",
    "\n",
    "plt.ylabel('percentage (#genres/#movies)')\n",
    "plt.title('Percentage by genres and Bechel Test pass')\n",
    "plt.xticks(ind,df_genres.columns)\n",
    "plt.legend((p1[0],p2[0]),('failed-Bechdel','passed-Bechdel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### One-Hot Encoding --- ML Preperation ######\n",
    "#################################################\n",
    "\n",
    "# Since many columns such as “crew”, “cast” contain information in json format, we need to \n",
    "# extract useful information from the columns and then perform one hot encoding.\n",
    "# We will transform our dataset into a all numeric matrix so that we can feed the data into \n",
    "# our machine learning model.\n",
    "# To look at the structure of column (eg.”cast”), we can use: df.loc[0,’cast’]\n",
    "\n",
    "def feature_engineering(column_name, df, json_name):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        column_name: the column name in the dataframe that contains a json file that needs to \n",
    "        conduct feature engineering on \n",
    "        \n",
    "        df: dataframe that perform feature engineering on\n",
    "        \n",
    "        json_name: name in the json file that we want to extract\n",
    "    \n",
    "    Returns: new dataframe after feature engineering\n",
    "    \"\"\"\n",
    "    \n",
    "    name = {}\n",
    "\n",
    "    for item in df[column_name]:\n",
    "        group = json.loads(item)\n",
    "        for it in group:\n",
    "            if it[json_name] not in name:\n",
    "                name[it[json_name]] = 1\n",
    "            else:\n",
    "                name[it[json_name]] += 1\n",
    "    \n",
    "    final = {}\n",
    "    index = 0\n",
    "    for k,v in name.items():\n",
    "        if v > 1:\n",
    "            final[k] = index\n",
    "            index += 1\n",
    "    np_item = np.zeros((len(df),len(final)))\n",
    "    item_dict = {}\n",
    "    row = 0\n",
    "    for item in df[column_name]:\n",
    "        group = json.loads(item)\n",
    "        for it in group:\n",
    "            if it[json_name] in final:\n",
    "                index = final[it[json_name]]\n",
    "                np_item[row][index] = 1\n",
    "        row += 1\n",
    "\n",
    "    df_item = pd.DataFrame(np_item, columns = list(final.keys()))\n",
    "    df_output = pd.concat([df,df_item],axis = 1)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF2 expands all the json data of cast and makes new columns for each one before deleting\n",
    "# the original cast column.\n",
    "df2 = feature_engineering(\"cast\", df, \"name\")\n",
    "df2 = df2.drop('cast', axis = 1)\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF3 expands all the json data of crew and makes new columns for each one before deleting\n",
    "# the original crew column.\n",
    "crew_name = {}\n",
    "\n",
    "# Director\n",
    "for item in df2['crew']:\n",
    "    crew = json.loads(item)\n",
    "    for it in crew:\n",
    "        if it['job'] == 'Director':\n",
    "            if it['name'] not in crew_name:\n",
    "                crew_name[it['name']] = 1\n",
    "            else:\n",
    "                crew_name[it['name']]+=1\n",
    "\n",
    "\n",
    "# Set the appear tims for Actors\n",
    "final_crew = {}\n",
    "index = 0\n",
    "for k,v in crew_name.items():\n",
    "    if v > 0:\n",
    "        final_crew[k] = index\n",
    "        index += 1\n",
    "# print(len(final_crew))\n",
    "\n",
    "np_crew = np.zeros((len(df2), len(final_crew)))\n",
    "row = 0\n",
    "for item in df2['crew']:\n",
    "    crew = json.loads(item)\n",
    "    for it in crew:\n",
    "        if it['job'] == 'Director':\n",
    "            if it['name'] in final_crew:\n",
    "                index = final_crew[it['name']]\n",
    "                np_crew[row][index] = 1\n",
    "    row += 1\n",
    "\n",
    "df_crew = pd.DataFrame(np_crew, columns = list(final_crew.keys()))\n",
    "            \n",
    "df3 = pd.concat([df2, df_crew], axis = 1)\n",
    "print(df.shape)\n",
    "#df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same concept but for a multitude of json filled column entries across the entire\n",
    "# DataFrame. Each evolution is morphed into the next until we get to DF8 in this part.\n",
    "df3=df3.drop(['crew'],axis=1)\n",
    "#genres\n",
    "df4 = feature_engineering(\"genres\", df3, \"name\")\n",
    "df4 = df4.drop(['genres'], axis = 1)\n",
    "#keywords\n",
    "df5 = feature_engineering('keywords', df4, 'name')\n",
    "df5 = df5.drop(['keywords'], axis = 1)\n",
    "#production_companies\n",
    "df6 = feature_engineering('production_companies',df5,'name')\n",
    "df6 = df6.drop(['production_companies'],axis=1)\n",
    "#production_countries\n",
    "df7 = feature_engineering('production_countries',df6,'name')\n",
    "df7 = df7.drop(['production_countries'],axis=1)\n",
    "#spoken_languages\n",
    "df8 = feature_engineering('spoken_languages',df7,'iso_639_1')\n",
    "df8 = df8.drop(['spoken_languages'],axis=1)\n",
    "\n",
    "# movieName, filmInfo, and award columns do not exist -- possible artifacts from team?\n",
    "\n",
    "df8.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_CLEAN is created from DF8 sans the below columns. It will then be encoded into OneHot,\n",
    "# and then hopefully fit into training sets to create models.\n",
    "df_clean = df8.drop([\"movie_title\", \"original_title\", \"overview\", \"tagline\", \"title\", \"original_language\",\n",
    "                    \"status\", \"release_date\"], axis=1)\n",
    "\n",
    "print(df_clean.shape)\n",
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging for 2 cells below ValueError\n",
    "# Ended up being easier to just drop the two problem rows containing NaNs\n",
    "df_clean = df_clean.dropna(axis='index', how='any')\n",
    "\n",
    "print(f\"Number of null values in entire DF: {df_clean.isnull().sum().sum()}\\n\")\n",
    "\n",
    "# If non-float types exist they'll be printed\n",
    "for dtype in df_clean.dtypes:\n",
    "    if dtype != float:\n",
    "        print(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#?                      Big Brain Stuff Ahead                    ?#\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# Model Training --- I replaced winner with Bechdel_Test\n",
    "X = df_clean[df_clean.columns.difference(['Bechdel_Test'])]\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "y = df_clean['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# test_size: what proportion of original data is used for test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, train_size=0.75, random_state=90001, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.95)\n",
    "fit = pca.fit(X_train)\n",
    "\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression(penalty='elasticnet', multi_class='ovr', n_jobs=-1, l1_ratio=0, random_state=288, solver='saga', max_iter=5000, verbose=10)\n",
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for One Observation\n",
    "predicted = logisticRegr.predict(X_test)\n",
    "print(logisticRegr.predict(X_test))\n",
    "print(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "print(f\"Total - Y_Test: {len(y_test)}\")\n",
    "print(f\"Total - Predicted: {len(predicted)}\\n\")\n",
    "\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\\n\")\n",
    "\n",
    "sensitivity = tp/(tp+fn)\n",
    "print(f\"Sensetivity / True Positive Rate: {sensitivity}\\n\")\n",
    "\n",
    "specificity = tn/(tn+fp)\n",
    "print(f\"Specificity / True Negative Rate: {specificity}\\n\")\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "print(f\"Precision / Positive Predictive Value: {precision}\\n\")\n",
    "\n",
    "npv = tn/(tn+fn)\n",
    "print(f\"Negative Predictive Value: {npv}\\n\")\n",
    "\n",
    "miss_rate = fn/(fn+tp)\n",
    "print(f\"Miss Rate / False Negative Rate: {miss_rate}\\n\")\n",
    "\n",
    "fall_out = fp/(fp+tn)\n",
    "print(f\"Fall-Out / False Positive Rate: {fall_out}\\n\")\n",
    "\n",
    "fdr = fp/(fp+tp)\n",
    "print(f\"False Discovery Rate: {fdr}\\n\")\n",
    "\n",
    "fOMr = fn/(fn+tn)\n",
    "print(f\"False Omission Rate: {fOMr}\\n\")\n",
    "\n",
    "threat_score = tp/(tp+fn+fp)\n",
    "print(f\"Threat Score / Critical Success Index: {threat_score}\\n\")\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "\n",
    "f1_score = (2*tp)/((2*tp)+fp+fn)\n",
    "print(f\"F1 Score / Harmonic Mean of Precision(PPV) and Sensetivity(TPR): {f1_score}\\n\")\n",
    "\n",
    "mcc = ((tp*tn)-(fp*fn))/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(f\"Matthews Correlation Coefficient: {mcc}\\n\")\n",
    "\n",
    "informedness = (sensitivity+specificity-1)\n",
    "print(f\"Informedness / Bookmaker Informedness: {informedness}\\n\")\n",
    "\n",
    "markedness = (precision+npv-1)\n",
    "print(f\"Markedness: {markedness}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-fold Cross validation\n",
    "\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#skf = StratifiedKFold()\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(random_state=55)\n",
    "\n",
    "sumAccuracy = []\n",
    "#for train,test in skf.split(X,y):\n",
    "for train,test in sss.split(X,y):\n",
    "    df_train = df_clean.iloc[train]\n",
    "    df_test = df_clean.iloc[test]\n",
    "    train_X = df_train[df_clean.columns.difference(['Bechdel_Test'])]\n",
    "    train_y = df_train['winner']\n",
    "    test_X = df_test[df_clean.columns.difference(['Bechdel_Test'])]\n",
    "    test_y = df_test['winner']\n",
    "    logisticRegr.fit(train_X, train_y)\n",
    "    sumAccuracy.append(logisticRegr.score(test_X, test_y))\n",
    "avg = np.mean(sumAccuracy)\n",
    "print(f\"\\n\\n3-Fold Cross Validation Mean Score: {avg}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
